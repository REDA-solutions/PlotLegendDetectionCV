{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "932c7a72",
   "metadata": {},
   "source": [
    "# Find a Legend Challenge - Starter Notebook\n",
    "\n",
    "link:  https://xeek.ai/challenges/extract-crossplot-markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc7ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add team name and model name here ###\n",
    "team_name = 'Team_name' \n",
    "model_name = 'model_name'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df9b253",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "    Througout the scientific community, a vast amount of information is contained within figures in papers, reports, and books. Without the raw data, this information can be lost altogether. We can increase our collective knowledge as a community if we develop a way to extract this information and convert it to a useful format for agregation and downstream analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5892e40",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "    Plot legend\n",
    "    \n",
    "    The goal of this challenge is to be able to extract the plot elements from the legend into a datatable. Elements in the legend will be listed in the order they appear on the legend and will be separated by a space. \n",
    "    \n",
    "    Ex:['Type A' 'Type B' 'Type C'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6073104f",
   "metadata": {},
   "source": [
    "## Data description\n",
    "    1. Image files containing one graph per file.\n",
    "    2. CSV file containing the image file name and legend elements. These labels are to be used to train and test the model on the associated graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ded45e",
   "metadata": {},
   "source": [
    "## Shared imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145f14f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import random as rnd\n",
    "import copy\n",
    "import re\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4000f542",
   "metadata": {},
   "source": [
    "## Dataset paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e59a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"./raw_data\" # Adjust this path to reflect where the data is stored on your personal computer\n",
    "IMAGE_DATASET_PATH = f\"{DATA_ROOT}/images\"\n",
    "LABELS_DATA_PATH = f\"{DATA_ROOT}/labels\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91068041",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DATASET_PATH=f\"{DATA_ROOT}/processed\"\n",
    "MODELS_ROOT_PATH=f\"./models\"\n",
    "MODEL_PATH=f\"{MODELS_ROOT_PATH}/{model_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f312b2b",
   "metadata": {},
   "source": [
    "## Data file exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414f9a91",
   "metadata": {},
   "outputs": [],
   "source": [
    " def read_image_filenames(path):\n",
    "    extensions = [\"*.png\"]\n",
    "    image_filenames = []\n",
    "    for ext in extensions:\n",
    "        image_filenames.extend(glob(os.path.join(path, ext)))\n",
    "    return image_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6873f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filenames = read_image_filenames(IMAGE_DATASET_PATH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f24765",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(image_filenames[0:5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41cb247",
   "metadata": {},
   "outputs": [],
   "source": [
    " def read_label_filenames(path):\n",
    "    extensions = [\"*.csv\"]\n",
    "    label_filenames = []\n",
    "    for ext in extensions:\n",
    "        label_filenames.extend(glob(os.path.join(path, ext)))\n",
    "    return label_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0935702",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_filenames = read_label_filenames(LABELS_DATA_PATH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf978a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(label_filenames) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68658f17",
   "metadata": {},
   "source": [
    "## Import data labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2292d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_labels (label):\n",
    "    labels = pd.read_csv(label[0])\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be5e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = import_labels(label_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fd0c6d",
   "metadata": {},
   "source": [
    "## Preview data\n",
    "    Here are the first 5 examples of the labels. Each row corresponds to a different graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33f9c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(labels.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e83fbdc",
   "metadata": {},
   "source": [
    "## Image import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd6ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_filenames):\n",
    "    image = cv2.imread(image_filenames) \n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13e256c",
   "metadata": {},
   "source": [
    "## Preview selected images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2a0303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_images(image_filenames):\n",
    "    figsize=(20,20)\n",
    "    nrows = len(image_filenames)\n",
    "    ncols = 1\n",
    "    fig, (axes) = plt.subplots(nrows, ncols, figsize=figsize, dpi=120)\n",
    "\n",
    "    for i in range(nrows):\n",
    "        img_filename = image_filenames[i]\n",
    "        image = read_image(img_filename)\n",
    "\n",
    "        axis = axes[i] if nrows > 1 else axes\n",
    "        axis.imshow(image)\n",
    "\n",
    "        title = os.path.basename(img_filename)\n",
    "        axis.set_title(title)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb6e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREVIEW_IMAGES_COUNT=5\n",
    "rnd.seed(101)\n",
    "preview_image_filenames=rnd.sample(image_filenames, k=PREVIEW_IMAGES_COUNT)\n",
    "pprint(preview_image_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9752a956",
   "metadata": {},
   "source": [
    "One way to tackle this problem is to consider the coordinates of the image elements. Here are the first 5 graphs as an example. Each graph is saved as separate png file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2ec30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_images(preview_image_filenames) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8d3245",
   "metadata": {},
   "source": [
    "## Potential pipeline code\n",
    "    The following code can be used to create your model pipeline. These functions outline suggested steps to help create the model. These functions are suggestions and you may change or edit as you see fit to create the desired functionality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eea0d4",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a731fa",
   "metadata": {},
   "outputs": [],
   "source": [
    " def process_data(image_dataset_path, PROCESSED_DATASET_PATH):\n",
    "    \"\"\"\n",
    "    Includes splitting, scaling, or extracting features from raw source images, which can then be used to train the model.    \n",
    "    \"\"\"\n",
    "    ### PUT YOUR CODE HERE ###\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb36d3a",
   "metadata": {},
   "source": [
    "## Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0845bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(PROCESSED_DATASET_PATH, labels):\n",
    "    \"\"\"\n",
    "    Split dataset files into train and test datasets.\n",
    "    Depending on your method of data processing, model training, and model testing, we recommend a method that doesn't copy/move images.\n",
    "    Instead, it returns lists of image filenames per each dataset. Modify subsequent code to match your method.\n",
    "    \"\"\"    \n",
    "    train_image_filenames = []\n",
    "    train_labels = []\n",
    "    test_image_filenames = []\n",
    "    test_labels = []\n",
    "    \n",
    "    ### PUT YOUR CODE HERE ###\n",
    "    \n",
    "    return train_image_filenames, train_labels, test_image_filenames, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df531c8",
   "metadata": {},
   "source": [
    "## Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbec290d",
   "metadata": {},
   "outputs": [],
   "source": [
    " def train_model(train_image_filenames, train_labels, MODEL_PATH):\n",
    "        \n",
    "    \"\"\"\n",
    "    Train your model on provided graphs and labels.\n",
    "    \"\"\"\n",
    "        \n",
    "    ### PUT YOUR CODE HERE ###\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5268461",
   "metadata": {},
   "source": [
    "## Model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975a2a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_image_filenames, test_labels,  MODEL_PATH):\n",
    "\n",
    "    ### PUT YOUR CODE HERE ###\n",
    "    \n",
    "    \"\"\"\n",
    "    Test your model's performance here on the split provided data. It may be helpful to define some metrics to evaluate the model's performance. \n",
    "    Note: submissions will be evaluated based on lenshtein distance of the predictions and key.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    metrics = {}\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943e2184",
   "metadata": {},
   "source": [
    "## Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c19bc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(image_filenames, MODEL_PATH):\n",
    "    \n",
    "    \"\"\"\n",
    "    Add functions defined above to run inference on unlabeled data. This function will be used to for the final submission of the notebook and evaluation. \n",
    "    The function should return predictions_sample_name and predicted_legend.\n",
    "    \n",
    "    Currently, arguments include the model path and image filenames. Please edit the inputs in the submission inference pipeline below if you utilize another method.\n",
    "    \"\"\"\n",
    "\n",
    "    ### PUT YOUR CODE HERE ####\n",
    "    predictions_sample_name = []\n",
    "    predicted_legend = []\n",
    "    \n",
    "    \n",
    "    ### Remove and add your model results here ###\n",
    "    predictions_sample_name = labels.sample_name\n",
    "    predicted_legend = labels.legend\n",
    "    \n",
    "    return predictions_sample_name, predicted_legend\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a88819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35c3e96f",
   "metadata": {},
   "source": [
    "## Submission inference pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a776a4",
   "metadata": {},
   "source": [
    "    Model generated predicted_legend will be compared to known values. Results will be evaluated based on the inference time, levenshtein distance, and F1 score of the model predictions. If you modified the inputs/outputs of previously listed functions, correct the following pipeline so it can handle images unknown to the user. \n",
    "    \n",
    "    The function needs to produce a CSV file containing the columns \"sample_name\" and \"legend\".\n",
    "    \n",
    "    The pip freeze print can be used to help make the environment requirements file (requirements.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ed230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff9750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA_ROOT = \"./test_dataset\"\n",
    "TEST_IMAGE_DATASET_PATH = f\"{TEST_DATA_ROOT}/images\"\n",
    "TEST_LABELS_DATA_PATH = f\"{TEST_DATA_ROOT}/labels\"\n",
    "TEST_INFERENCE_RESULTS_PATH = f\"{TEST_DATA_ROOT}/inference_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ffd0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    " def run_inference_pipeline(TEST_IMAGE_DATASET_PATH, TEST_INFERENCE_RESULTS_PATH, PROCESSED_DATASET_PATH, MODEL_PATH):\n",
    "    \n",
    "    print(\"Runing inference with parameters:\")\n",
    "    print(f\"* OS                          : {platform.system()}, {platform.release()}\")\n",
    "    python_version = str(sys.version).replace('\\n', ' ')\n",
    "    print(f\"* Python version              : {python_version}\")\n",
    "    print(\"\\n-- pip freeze start ---\")\n",
    "    !pip freeze\n",
    "    print(\"-- pip freeze end ---\")\n",
    "\n",
    "    os.makedirs(TEST_INFERENCE_RESULTS_PATH, exist_ok=True)\n",
    "    \n",
    "    image_filenames = read_image_filenames(TEST_IMAGE_DATASET_PATH)\n",
    "           \n",
    "    ts_start = perf_counter()\n",
    "    \n",
    "    process_data(TEST_IMAGE_DATASET_PATH, PROCESSED_DATASET_PATH)\n",
    "    \n",
    "    ts_after_processing = perf_counter()\n",
    "\n",
    "    predictions_sample_name, predicted_legend = run_inference(image_filenames, MODEL_PATH) \n",
    "    \n",
    "    ts_after_test = perf_counter()\n",
    "    \n",
    "    Processing_time_s = ts_after_processing-ts_start\n",
    "    Inference_time_s = ts_after_test-ts_after_processing\n",
    "    \n",
    "    print(f\"Processing time: {ts_after_processing-ts_start:.2f} sec.\")\n",
    "    print(f\"Inference time: {ts_after_test-ts_after_processing:.2f} sec.\")\n",
    "    \n",
    "    \n",
    "    inference_results = {'sample_name': predictions_sample_name,\n",
    "                         'legend': predicted_legend}\n",
    "    inference_results_df = pd.DataFrame(inference_results)\n",
    "        \n",
    "    inference_results_df.to_csv(f\"{TEST_INFERENCE_RESULTS_PATH}/{team_name}_{model_name}_results.csv\", index = False)\n",
    "    \n",
    "    print(inference_results_df)\n",
    "\n",
    "    print(f\"The submission file   : {TEST_INFERENCE_RESULTS_PATH}/{team_name}_{model_name}_results.csv\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6643212c",
   "metadata": {},
   "outputs": [],
   "source": [
    " run_inference_pipeline(\n",
    "    TEST_IMAGE_DATASET_PATH,     \n",
    "    TEST_INFERENCE_RESULTS_PATH, \n",
    "    PROCESSED_DATASET_PATH, \n",
    "    MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a082c34d",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6f2181",
   "metadata": {},
   "source": [
    "Upload the inference results CSV file under the challenge on http://xeek.ai/ to score your model and update the leaderboard. Finalist will be invited to submit their notebook for final review and scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd53d235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74c6d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
