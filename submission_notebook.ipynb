{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "932c7a72",
   "metadata": {},
   "source": [
    "# Find a Legend Challenge - Submission Notebook\n",
    "\n",
    "Competition:  https://xeek.ai/challenges/extract-crossplot-markers <br>\n",
    "Repository: https://github.com/REDA-solutions/AdvancedCV-competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc7ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = 'Team Barenstark' \n",
    "model_name = 'best.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ded45e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "145f14f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ti-he\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import torch\n",
    "\n",
    "from models_ocr.preprocessing.preprocessor import Preprocessor # import of our class --> see repository\n",
    "from models_ocr.pytesseract_model import PytesseractModel # import of our class --> see repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ad584c",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439b4561",
   "metadata": {},
   "source": [
    "![Model Architecture](misc/model_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c3e96f",
   "metadata": {},
   "source": [
    "## Submission inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ed230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ff9750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA_ROOT = \"raw_data/helvetios_challenge_dataset_test\"\n",
    "TEST_IMAGE_DATASET_PATH = f\"{TEST_DATA_ROOT}/images\"\n",
    "TEST_LABELS_DATA_PATH = f\"{TEST_DATA_ROOT}/labels\"\n",
    "TEST_INFERENCE_RESULTS_PATH = f\"results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2ffd0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_pipeline(TEST_IMAGE_DATASET_PATH, TEST_INFERENCE_RESULTS_PATH):\n",
    "   \n",
    "   print(f\"* OS                          : {platform.system()}, {platform.release()}\")\n",
    "   python_version = str(sys.version).replace('\\n', ' ')\n",
    "   print(f\"* Python version              : {python_version}\")\n",
    "\n",
    "   os.makedirs(TEST_INFERENCE_RESULTS_PATH, exist_ok=True)\n",
    "         \n",
    "   ts_start = perf_counter()\n",
    "   \n",
    "   model = torch.hub.load('../yolov5/', 'custom', path='models_detection/best.pt', source='local')\n",
    "   preprocessor = Preprocessor(deskew=True)\n",
    "   tesseract = PytesseractModel(preprocessor=preprocessor, confidence=15)\n",
    "\n",
    "   imgs = TEST_IMAGE_DATASET_PATH + r'/*.png'  \n",
    "   imgs = list(glob(imgs))[:5]\n",
    "   \n",
    "   results = []\n",
    "   sample_names = []\n",
    "\n",
    "   for img in imgs:\n",
    "      legend = model(img)\n",
    "      legend = legend.crop()\n",
    "      if len(legend) == 0:\n",
    "         results.append(np.nan)\n",
    "      else:\n",
    "         legend = legend[0]['im']\n",
    "         prediction = tesseract.predict(legend)\n",
    "         prediction_str = \"[\"\n",
    "         for word in prediction: prediction_str += f\"'{word}' \"\n",
    "         prediction_str = prediction_str.strip()\n",
    "         prediction_str += \"]\"\n",
    "         results.append(prediction_str)\n",
    "      sample_names.append(img.split(\"\\\\\")[1])\n",
    "   \n",
    "   ts_after_test = perf_counter()\n",
    "   \n",
    "   print(f\"Inference time: {ts_after_test-ts_start:.2f} sec.\")\n",
    "   \n",
    "   inference_results = {'sample_name': sample_names,\n",
    "                        'legend': results}\n",
    "   inference_results_df = pd.DataFrame(inference_results)\n",
    "      \n",
    "   inference_results_df.to_csv(f\"{TEST_INFERENCE_RESULTS_PATH}/{team_name}_{model_name}_results.csv\", index = False)\n",
    "   \n",
    "   print(inference_results_df)\n",
    "\n",
    "   print(f\"The submission file   : {TEST_INFERENCE_RESULTS_PATH}/{team_name}_{model_name}_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6643212c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* OS                          : Windows, 10\n",
      "* Python version              : 3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-9-gf9ca365 Python-3.10.8 torch-1.13.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n",
      "Saved 1 image to \u001b[1mruns\\detect\\exp1279\u001b[0m\n",
      "Saved results to runs\\detect\\exp1279\n",
      "\n",
      "Saved 1 image to \u001b[1mruns\\detect\\exp1280\u001b[0m\n",
      "Saved results to runs\\detect\\exp1280\n",
      "\n",
      "Saved 1 image to \u001b[1mruns\\detect\\exp1281\u001b[0m\n",
      "Saved results to runs\\detect\\exp1281\n",
      "\n",
      "Saved 1 image to \u001b[1mruns\\detect\\exp1282\u001b[0m\n",
      "Saved results to runs\\detect\\exp1282\n",
      "\n",
      "Saved 1 image to \u001b[1mruns\\detect\\exp1283\u001b[0m\n",
      "Saved results to runs\\detect\\exp1283\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 5.15 sec.\n",
      "                sample_name                                 legend\n",
      "0  20220915195651573677.png  ['drt' 'qn' 'Â©' 'deo' 'RE' '@' 'ber']\n",
      "1  20220915195652176684.png                                    NaN\n",
      "2  20220915195652713648.png                      ['Mobility' 'ae']\n",
      "3  20220915195653681519.png                                ['exe']\n",
      "4  20220915195654121931.png                                    NaN\n",
      "The submission file   : results/Team Barenstark_best.pt_results.csv\n"
     ]
    }
   ],
   "source": [
    "run_inference_pipeline(TEST_IMAGE_DATASET_PATH, TEST_INFERENCE_RESULTS_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e0acaf148705ed9ed86cc5cad12259d7985e30670e5686e5f55604a9b3b84a55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
